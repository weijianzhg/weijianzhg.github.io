<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://weijianzhg.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://weijianzhg.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-08-31T19:30:09+00:00</updated><id>https://weijianzhg.github.io/feed.xml</id><title type="html">blank</title><subtitle>Weijian Zhang&apos;s personal website and personal blog </subtitle><entry><title type="html">Building Custom Machine Learning Models</title><link href="https://weijianzhg.github.io/blog/2021/custom-machine-learning-model/" rel="alternate" type="text/html" title="Building Custom Machine Learning Models"/><published>2021-12-06T00:00:00+00:00</published><updated>2021-12-06T00:00:00+00:00</updated><id>https://weijianzhg.github.io/blog/2021/custom-machine-learning-model</id><content type="html" xml:base="https://weijianzhg.github.io/blog/2021/custom-machine-learning-model/"><![CDATA[<p>Sometimes, in order to meet a specific business need it is best to create a custom machine learning model. In this article we discuss how to create such models. We show how use the custom machine learning models within the scikit-learn ecosystem. For example, we can apply scikit-learn’s <code class="language-plaintext highlighter-rouge">GridSearchCV</code> on our custom machine learning models to find the best hyperparameters.</p> <h2 id="basic-components-of-a-machine-learning-model">Basic Components of a Machine Learning Model</h2> <p>A (supervised) machine learning model has two main components: <code class="language-plaintext highlighter-rouge">fit</code> and <code class="language-plaintext highlighter-rouge">predict</code>. We use the <code class="language-plaintext highlighter-rouge">fit</code> method to learn from data and use <code class="language-plaintext highlighter-rouge">predict</code> to make predictions on new data.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MLModel</span><span class="p">():</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sh">"</span><span class="s">train the model on a dataset</span><span class="sh">"</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sh">"</span><span class="s">predict y on unseen dataset</span><span class="sh">"</span>
</code></pre></div></div> <h2 id="a-simple-custom-machine-learning-model-for-classifying-iris-species">A Simple Custom Machine Learning Model For Classifying Iris Species</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/iris-480.webp 480w,/assets/img/iris-800.webp 800w,/assets/img/iris-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/iris.jpeg" class="rounded z-depth-1" width="120px" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Let’s consider the classic <a href="https://archive.ics.uci.edu/ml/datasets/iris">Iris dataset</a>. The dataset consists of samples from three Iris species (Iris setosa, Iris virginica, Iris versicolor) with four features (sepal length, sepal width, petal length, petal width). We can load it from <code class="language-plaintext highlighter-rouge">sklearn.datasets</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>sepal length (cm)</th> <th>sepal width (cm)</th> <th>petal length (cm)</th> <th>petal width (cm)</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>5.1</td> <td>3.5</td> <td>1.4</td> <td>0.2</td> </tr> <tr> <th>1</th> <td>4.9</td> <td>3.0</td> <td>1.4</td> <td>0.2</td> </tr> <tr> <th>2</th> <td>4.7</td> <td>3.2</td> <td>1.3</td> <td>0.2</td> </tr> <tr> <th>3</th> <td>4.6</td> <td>3.1</td> <td>1.5</td> <td>0.2</td> </tr> <tr> <th>4</th> <td>5.0</td> <td>3.6</td> <td>1.4</td> <td>0.2</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>145</th> <td>6.7</td> <td>3.0</td> <td>5.2</td> <td>2.3</td> </tr> <tr> <th>146</th> <td>6.3</td> <td>2.5</td> <td>5.0</td> <td>1.9</td> </tr> <tr> <th>147</th> <td>6.5</td> <td>3.0</td> <td>5.2</td> <td>2.0</td> </tr> <tr> <th>148</th> <td>6.2</td> <td>3.4</td> <td>5.4</td> <td>2.3</td> </tr> <tr> <th>149</th> <td>5.9</td> <td>3.0</td> <td>5.1</td> <td>1.8</td> </tr> </tbody> </table> <p>150 rows × 4 columns</p> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>sepal length (cm)</th> <th>sepal width (cm)</th> <th>petal length (cm)</th> <th>petal width (cm)</th> </tr> </thead> <tbody> <tr> <th>count</th> <td>150.000000</td> <td>150.000000</td> <td>150.000000</td> <td>150.000000</td> </tr> <tr> <th>mean</th> <td>5.843333</td> <td>3.057333</td> <td>3.758000</td> <td>1.199333</td> </tr> <tr> <th>std</th> <td>0.828066</td> <td>0.435866</td> <td>1.765298</td> <td>0.762238</td> </tr> <tr> <th>min</th> <td>4.300000</td> <td>2.000000</td> <td>1.000000</td> <td>0.100000</td> </tr> <tr> <th>25%</th> <td>5.100000</td> <td>2.800000</td> <td>1.600000</td> <td>0.300000</td> </tr> <tr> <th>50%</th> <td>5.800000</td> <td>3.000000</td> <td>4.350000</td> <td>1.300000</td> </tr> <tr> <th>75%</th> <td>6.400000</td> <td>3.300000</td> <td>5.100000</td> <td>1.800000</td> </tr> <tr> <th>max</th> <td>7.900000</td> <td>4.400000</td> <td>6.900000</td> <td>2.500000</td> </tr> </tbody> </table> </div> <p>It’s clear that sepal length, sepal width, petal length, and petal width should be positive numbers.</p> <p>Let’s create a simple custom machine learning model: train the model using Support Vector Classification (SVC) but only make predictions if all the features are positive, return <code class="language-plaintext highlighter-rouge">unknown</code> otherwise.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>


<span class="k">class</span> <span class="nc">MLModel</span><span class="p">():</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="sh">'</span><span class="s">linear</span><span class="sh">'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span>
        <span class="n">self</span><span class="p">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span>
        <span class="n">self</span><span class="p">.</span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="nc">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">C</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">kernel</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sh">"</span><span class="s">train the model on a dataset</span><span class="sh">"</span>
        <span class="n">self</span><span class="p">.</span><span class="n">clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="sh">"</span><span class="s">predict y on unseen dataset</span><span class="sh">"</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">X</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
            <span class="nf">if </span><span class="p">(</span><span class="n">row</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="nf">all</span><span class="p">():</span>
                <span class="n">prediction</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="nf">to_frame</span><span class="p">().</span><span class="n">T</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">prediction</span> <span class="o">=</span> <span class="sh">'</span><span class="s">unknown</span><span class="sh">'</span>
            <span class="n">predictions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">predictions</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">MLModel</span><span class="p">()</span>
</code></pre></div></div> <p>We can now train the model on the Iris dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div> <p>To try our trained model we create three test samples. Note that the second sample has <code class="language-plaintext highlighter-rouge">0.0</code> sepal length and the third sample has sepal width equal to <code class="language-plaintext highlighter-rouge">-1.0</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_new</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
    <span class="sh">'</span><span class="s">sepal length (cm)</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">2.3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">6.3</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">sepal width (cm)</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">petal length (cm)</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.4</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">,</span> <span class="mf">5.4</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">petal width (cm)</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">]</span>
<span class="p">})</span>
<span class="n">X_new</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>sepal length (cm)</th> <th>sepal width (cm)</th> <th>petal length (cm)</th> <th>petal width (cm)</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>2.3</td> <td>2.5</td> <td>1.4</td> <td>2.0</td> </tr> <tr> <th>1</th> <td>0.0</td> <td>3.0</td> <td>4.2</td> <td>2.3</td> </tr> <tr> <th>2</th> <td>6.3</td> <td>-1.0</td> <td>5.4</td> <td>1.9</td> </tr> </tbody> </table> </div> <p>As expected our model only returns a prediction for first sample and returns <code class="language-plaintext highlighter-rouge">unknown</code> for the second and the third samples.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0, 'unknown', 'unknown']
</code></pre></div></div> <h2 id="using-custom-machine-learning-models-within-the-scikit-learn-ecosystem">Using Custom Machine Learning Models within the Scikit-learn Ecosystem</h2> <p>In order to use our custom machine learning model within the scikit-learn ecosystem, we need to provide a few other methods:</p> <ul> <li><code class="language-plaintext highlighter-rouge">get_params</code>: returns a dict of parameters of the machine learning model.</li> <li><code class="language-plaintext highlighter-rouge">set_params</code>: takes a dictionary of parameters as input and sets the parameter of the machine learning model.</li> <li><code class="language-plaintext highlighter-rouge">score</code>: provides a default evaluation criterion for the problem they are designed to solve.</li> </ul> <p>We can either implement these methods ourselves or just inherit these methods from <code class="language-plaintext highlighter-rouge">sklearn.base.BaseEstimator</code> and <code class="language-plaintext highlighter-rouge">sklearn.base.ClassifierMixin</code>.</p> <p><code class="language-plaintext highlighter-rouge">BaseEstimator</code> provides the implementation of the <code class="language-plaintext highlighter-rouge">get_params</code> and <code class="language-plaintext highlighter-rouge">set_params</code> methods. <code class="language-plaintext highlighter-rouge">ClassifierMixin</code> provides the implementation of the <code class="language-plaintext highlighter-rouge">score</code> method as the mean accuracy.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>


<span class="k">class</span> <span class="nc">MLModel</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="sh">'</span><span class="s">linear</span><span class="sh">'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span>
        <span class="n">self</span><span class="p">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span>
        <span class="n">self</span><span class="p">.</span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="nc">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">C</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">kernel</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sh">"</span><span class="s">train the model on a dataset</span><span class="sh">"</span>
        <span class="n">self</span><span class="p">.</span><span class="n">clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="sh">"</span><span class="s">predict y on unseen dataset</span><span class="sh">"</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">X</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
            <span class="nf">if </span><span class="p">(</span><span class="n">row</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="nf">all</span><span class="p">():</span>
                <span class="n">prediction</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="nf">to_frame</span><span class="p">().</span><span class="n">T</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">prediction</span> <span class="o">=</span> <span class="sh">'</span><span class="s">unknown</span><span class="sh">'</span>
            <span class="n">predictions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">predictions</span>


<span class="n">model</span> <span class="o">=</span> <span class="nc">MLModel</span><span class="p">()</span>
</code></pre></div></div> <p>Since we’ve defined <code class="language-plaintext highlighter-rouge">MLModel</code> as a subclass of <code class="language-plaintext highlighter-rouge">BaseEstimator</code> and <code class="language-plaintext highlighter-rouge">ClassifierMixin</code>, we can use <code class="language-plaintext highlighter-rouge">get_params</code> to retrieve all the parameters and use <code class="language-plaintext highlighter-rouge">score</code> to compute the mean accuracy on the test dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nf">get_params</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'C': 1.0, 'kernel': 'linear'}
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1.0
</code></pre></div></div> <p>Our custom machine learning model also works fine with scikit-learn’s <code class="language-plaintext highlighter-rouge">GridSearchCV</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">kernel</span><span class="sh">'</span><span class="p">:(</span><span class="sh">'</span><span class="s">linear</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">rbf</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>


<span class="n">clf</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>GridSearchCV(estimator=MLModel(),
             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clf</span><span class="p">.</span><span class="n">best_params_</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'C': 1, 'kernel': 'linear'}
</code></pre></div></div> <p>Note that for regression problems we need to use <code class="language-plaintext highlighter-rouge">RegressorMixin</code> instead of <code class="language-plaintext highlighter-rouge">ClassifierMixin</code>, which implements the coefficient of determination of the prediction as the <code class="language-plaintext highlighter-rouge">score</code> method. See <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html">here</a> for more details.</p>]]></content><author><name></name></author><category term="machine-learning-engineering"/><category term="machine-learning,"/><category term="custom-model,"/><category term="scikit-learn"/><summary type="html"><![CDATA[Building a custom machine learning model with Scikit-learn base classes and use it within the scikit-learning ecosystem.]]></summary></entry><entry><title type="html">Feature Engineering in a Pipeline</title><link href="https://weijianzhg.github.io/blog/2021/feature-engineering/" rel="alternate" type="text/html" title="Feature Engineering in a Pipeline"/><published>2021-11-03T00:00:00+00:00</published><updated>2021-11-03T00:00:00+00:00</updated><id>https://weijianzhg.github.io/blog/2021/feature-engineering</id><content type="html" xml:base="https://weijianzhg.github.io/blog/2021/feature-engineering/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Feature engineering is a process of transforming the given dataset into a form which is easy for the machine learning model to interpret. If we have different transformation functions for training and prediction we may duplicate the same work and it’s harder to maintain (make some changes in one pipeline means we have to update the other pipeline as well).</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/feature-engineering-separate-480.webp 480w,/assets/img/feature-engineering-separate-800.webp 800w,/assets/img/feature-engineering-separate-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/feature-engineering-separate.png" class="img-fluid rounded z-depth-1" width="360px" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>One common practice in producitionzing machine learning models is to write a transformation <em>pipeline</em> so that we can use the same data transformation code for both training and prediction.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/feature-engineering-one-480.webp 480w,/assets/img/feature-engineering-one-800.webp 800w,/assets/img/feature-engineering-one-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/feature-engineering-one.png" class="img-fluid rounded z-depth-1" width="360px" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In this article, we discuss how we can use <a href="https://scikit-learn.org/stable/">scikit-learn</a> to build a feature engineering pipeline. Let’s first have a look at a few common transformations for numeric features and categorical features.</p> <h2 id="transforming-numerical-features">Transforming Numerical Features</h2> <p>One thing I really like about scikit-learn is that I can use the same ‘‘fit’’ and ‘‘predict’’ pattern for data preprocessing. For a preprocessor, the two methods are called <code class="language-plaintext highlighter-rouge">fit</code> and <code class="language-plaintext highlighter-rouge">transform</code>.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/feature-engineering-preprocessor-480.webp 480w,/assets/img/feature-engineering-preprocessor-800.webp 800w,/assets/img/feature-engineering-preprocessor-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/feature-engineering-preprocessor.png" class="img-fluid rounded z-depth-1" width="360px" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>We can use <code class="language-plaintext highlighter-rouge">SimpleImputer</code> to complete missing values and <code class="language-plaintext highlighter-rouge">StandardScaler</code> to standardize values by removing the mean and scaling to unit variance.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</code></pre></div></div> <p>Let’s create a simple example.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">n1</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">400</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">n2</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">n3</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span>
    <span class="p">}</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>n1</th> <th>n2</th> <th>n3</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>20.0</td> <td>0.1</td> <td>-20.0</td> </tr> <tr> <th>1</th> <td>300.0</td> <td>NaN</td> <td>-10.0</td> </tr> <tr> <th>2</th> <td>400.0</td> <td>0.5</td> <td>0.0</td> </tr> <tr> <th>3</th> <td>NaN</td> <td>0.6</td> <td>-30.0</td> </tr> <tr> <th>4</th> <td>100.0</td> <td>NaN</td> <td>NaN</td> </tr> </tbody> </table> </div> <p>We can have a look the mean of each column using the <code class="language-plaintext highlighter-rouge">.mean()</code> method.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>n1    205.0
n2      0.4
n3    -15.0
dtype: float64
</code></pre></div></div> <p>Here we create a <code class="language-plaintext highlighter-rouge">SimpleImputer</code> object with <code class="language-plaintext highlighter-rouge">strategy="mean"</code>. This means we fill the missing value using the mean along each column.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_imputer</span> <span class="o">=</span> <span class="nc">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">mean</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>We first fit our imputer <code class="language-plaintext highlighter-rouge">num_imputer</code> on our simple dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_imputer</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SimpleImputer()
</code></pre></div></div> <p>After fitting the model, the statistic, i.e., the fill value for each column, is <em>stored</em> within the imputer <code class="language-plaintext highlighter-rouge">num_imputer</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_imputer</span><span class="p">.</span><span class="n">statistics_</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([205. ,   0.4, -15. ])
</code></pre></div></div> <p>Now we can fill the missing values in our original dataset with the <code class="language-plaintext highlighter-rouge">transform</code> method. By the way, we can also apply fit and transform in one go with the <code class="language-plaintext highlighter-rouge">fit_transform</code> method.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imputed_features</span> <span class="o">=</span> <span class="n">num_imputer</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imputed_features</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[ 2.00e+01,  1.00e-01, -2.00e+01],
       [ 3.00e+02,  4.00e-01, -1.00e+01],
       [ 4.00e+02,  5.00e-01,  0.00e+00],
       [ 2.05e+02,  6.00e-01, -3.00e+01],
       [ 1.00e+02,  4.00e-01, -1.50e+01]])
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">type</span><span class="p">(</span><span class="n">imputed_features</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>numpy.ndarray
</code></pre></div></div> <p>The transformed features are stored as <code class="language-plaintext highlighter-rouge">numpy.ndarray</code>. We can convert it back to <code class="language-plaintext highlighter-rouge">pandas.DataFrame</code> with</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imputed_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">imputed_features</span><span class="p">,</span>
    <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imputed_df</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>n1</th> <th>n2</th> <th>n3</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>20.0</td> <td>0.1</td> <td>-20.0</td> </tr> <tr> <th>1</th> <td>300.0</td> <td>0.4</td> <td>-10.0</td> </tr> <tr> <th>2</th> <td>400.0</td> <td>0.5</td> <td>0.0</td> </tr> <tr> <th>3</th> <td>205.0</td> <td>0.6</td> <td>-30.0</td> </tr> <tr> <th>4</th> <td>100.0</td> <td>0.4</td> <td>-15.0</td> </tr> </tbody> </table> </div> <p>The cool thing is that now we can use the same statistic saved in <code class="language-plaintext highlighter-rouge">num_imputer</code> to transform other datasets. For example here we create a new dataset with only one row.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># New data
</span>
<span class="n">data_new</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">n1</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="bp">None</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">n2</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">n3</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="bp">None</span><span class="p">],</span>
    <span class="p">}</span>

<span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data_new</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_new</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>n1</th> <th>n2</th> <th>n3</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>None</td> <td>0.1</td> <td>None</td> </tr> </tbody> </table> </div> <p>We can apply <code class="language-plaintext highlighter-rouge">num_imputer.transform</code> on this new dataset to fill the missing values.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">num_imputer</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">df_new</span><span class="p">),</span>
    <span class="n">index</span><span class="o">=</span><span class="n">df_new</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df_new</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>n1</th> <th>n2</th> <th>n3</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>205.0</td> <td>0.1</td> <td>-15.0</td> </tr> </tbody> </table> </div> <p><code class="language-plaintext highlighter-rouge">StandardScaler</code> works in a similar way. Here we scale the dataset after the imputer step.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_scaler</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_scaler</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">imputed_df</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>StandardScaler()
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">num_scaler</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">imputed_df</span><span class="p">),</span>
    <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>n1</th> <th>n2</th> <th>n3</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>-1.361620</td> <td>-1.792843e+00</td> <td>-0.5</td> </tr> <tr> <th>1</th> <td>0.699210</td> <td>-3.317426e-16</td> <td>0.5</td> </tr> <tr> <th>2</th> <td>1.435221</td> <td>5.976143e-01</td> <td>1.5</td> </tr> <tr> <th>3</th> <td>0.000000</td> <td>1.195229e+00</td> <td>-1.5</td> </tr> <tr> <th>4</th> <td>-0.772811</td> <td>-3.317426e-16</td> <td>0.0</td> </tr> </tbody> </table> </div> <h2 id="transforming-categorical-features">Transforming Categorical Features</h2> <p><code class="language-plaintext highlighter-rouge">OneHotEncoder</code> is commonly used to transform categorical features. Essentially, for each unique value in the original categorical column, a new column is created to represent this value. Each column is filled up with zeros (the value exists) and ones (the value doesn’t exist).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>


<span class="n">cat_encoder</span> <span class="o">=</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">c1</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">Male</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Female</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Male</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Female</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Female</span><span class="sh">'</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">c2</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">Apple</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Orange</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Apple</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Banana</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Pear</span><span class="sh">'</span><span class="p">],</span>
    <span class="p">}</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">df</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>c1</th> <th>c2</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>Male</td> <td>Apple</td> </tr> <tr> <th>1</th> <td>Female</td> <td>Orange</td> </tr> <tr> <th>2</th> <td>Male</td> <td>Apple</td> </tr> <tr> <th>3</th> <td>Female</td> <td>Banana</td> </tr> <tr> <th>4</th> <td>Female</td> <td>Pear</td> </tr> </tbody> </table> </div> <p>Let’s first <code class="language-plaintext highlighter-rouge">fit</code> a one hot encoder to a dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cat_encoder</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>OneHotEncoder(handle_unknown='ignore')
</code></pre></div></div> <p>Note that the categories of each column is stored in attribute <code class="language-plaintext highlighter-rouge">.categories_</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cat_encoder</span><span class="p">.</span><span class="n">categories_</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[array(['Female', 'Male'], dtype=object),
 array(['Apple', 'Banana', 'Orange', 'Pear'], dtype=object)]
</code></pre></div></div> <p>Here is the encoded dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">cat_encoder</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="nf">toarray</span><span class="p">(),</span>
    <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">cat_encoder</span><span class="p">.</span><span class="nf">get_feature_names_out</span><span class="p">())</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>c1_Female</th> <th>c1_Male</th> <th>c2_Apple</th> <th>c2_Banana</th> <th>c2_Orange</th> <th>c2_Pear</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>0.0</td> <td>1.0</td> <td>1.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> </tr> <tr> <th>1</th> <td>1.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>1.0</td> <td>0.0</td> </tr> <tr> <th>2</th> <td>0.0</td> <td>1.0</td> <td>1.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> </tr> <tr> <th>3</th> <td>1.0</td> <td>0.0</td> <td>0.0</td> <td>1.0</td> <td>0.0</td> <td>0.0</td> </tr> <tr> <th>4</th> <td>1.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>1.0</td> </tr> </tbody> </table> </div> <p>We can now use <code class="language-plaintext highlighter-rouge">cat_encoder</code> to <code class="language-plaintext highlighter-rouge">transform</code> new dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_new</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">c1</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">Female</span><span class="sh">'</span><span class="p">],</span> <span class="sh">'</span><span class="s">c2</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">Orange</span><span class="sh">'</span><span class="p">]}</span>

<span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data_new</span><span class="p">)</span>

<span class="n">df_new</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>c1</th> <th>c2</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>Female</td> <td>Orange</td> </tr> </tbody> </table> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">cat_encoder</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">df_new</span><span class="p">).</span><span class="nf">toarray</span><span class="p">(),</span>
    <span class="n">index</span><span class="o">=</span><span class="n">df_new</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">cat_encoder</span><span class="p">.</span><span class="nf">get_feature_names_out</span><span class="p">())</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>c1_Female</th> <th>c1_Male</th> <th>c2_Apple</th> <th>c2_Banana</th> <th>c2_Orange</th> <th>c2_Pear</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>1.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>1.0</td> <td>0.0</td> </tr> </tbody> </table> </div> <h2 id="building-a-feature-engineering-pipeline">Building a Feature Engineering Pipeline</h2> <h3 id="make-a-pipeline">Make a Pipeline</h3> <p>For numerical features, we can make a <code class="language-plaintext highlighter-rouge">pipeline</code> to first fill the missing values with median and then apply standard scaler; for categorical features, we can make a <code class="language-plaintext highlighter-rouge">pipeline</code> to first fill the missing values with the word “missing” and then apply one hot encoder.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="n">numeric_transformer</span> <span class="o">=</span> <span class="nf">make_pipeline</span><span class="p">(</span><span class="nc">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">median</span><span class="sh">"</span><span class="p">),</span>
                                    <span class="nc">StandardScaler</span><span class="p">())</span>

<span class="n">categorical_transformer</span> <span class="o">=</span> <span class="nf">make_pipeline</span><span class="p">(</span>
            <span class="nc">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">constant</span><span class="sh">"</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="sh">"</span><span class="s">missing</span><span class="sh">"</span><span class="p">),</span>
            <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="sh">"</span><span class="s">ignore</span><span class="sh">"</span><span class="p">),)</span>

</code></pre></div></div> <p>The transformer pipelines can be used the same way as the individual transformers, i.e., we can <code class="language-plaintext highlighter-rouge">fit</code> a pipeline with some data and use this pipeline to <code class="language-plaintext highlighter-rouge">transform</code> new data. For example,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">n1</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">400</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">n2</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">n3</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span>
    <span class="p">}</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>n1</th> <th>n2</th> <th>n3</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>20.0</td> <td>0.1</td> <td>-20.0</td> </tr> <tr> <th>1</th> <td>300.0</td> <td>NaN</td> <td>-10.0</td> </tr> <tr> <th>2</th> <td>400.0</td> <td>0.5</td> <td>0.0</td> </tr> <tr> <th>3</th> <td>NaN</td> <td>0.6</td> <td>-30.0</td> </tr> <tr> <th>4</th> <td>100.0</td> <td>NaN</td> <td>NaN</td> </tr> </tbody> </table> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">numeric_transformer</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),
                ('standardscaler', StandardScaler())])
</code></pre></div></div> <p>Notice that the result is exactly the same as the example we give before (apply imputer and then scaler seperately).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">numeric_transformer</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">df</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>n1</th> <th>n2</th> <th>n3</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>-1.354113</td> <td>-1.950034</td> <td>-0.5</td> </tr> <tr> <th>1</th> <td>0.706494</td> <td>0.344124</td> <td>0.5</td> </tr> <tr> <th>2</th> <td>1.442425</td> <td>0.344124</td> <td>1.5</td> </tr> <tr> <th>3</th> <td>-0.029437</td> <td>0.917663</td> <td>-1.5</td> </tr> <tr> <th>4</th> <td>-0.765368</td> <td>0.344124</td> <td>0.0</td> </tr> </tbody> </table> </div> <h3 id="compose-a-column-transformer">Compose a Column Transformer</h3> <p>For a real life dataset we may have both numeric features and categorical features. It would be nice to selectively apply numeric transformation on the numeric features and categorical transformation on the categorical features. We can accomplish this goal by composing a <code class="language-plaintext highlighter-rouge">ColumnTransformer</code>.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/feature-engineering-selector-480.webp 480w,/assets/img/feature-engineering-selector-800.webp 800w,/assets/img/feature-engineering-selector-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/feature-engineering-selector.png" class="img-fluid rounded z-depth-1" width="660px" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The example below has columns with numeric values (<code class="language-plaintext highlighter-rouge">'n1'</code>, <code class="language-plaintext highlighter-rouge">'n2'</code>, <code class="language-plaintext highlighter-rouge">'n3'</code>) and categorical values (<code class="language-plaintext highlighter-rouge">'c1'</code>, <code class="language-plaintext highlighter-rouge">'c2'</code>).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">n1</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">400</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">n2</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">n3</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">c1</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">Male</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Female</span><span class="sh">'</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="sh">'</span><span class="s">Female</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Female</span><span class="sh">'</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">c2</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">Apple</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Orange</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Apple</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Banana</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Pear</span><span class="sh">'</span><span class="p">],</span>
    <span class="p">}</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">df</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>n1</th> <th>n2</th> <th>n3</th> <th>c1</th> <th>c2</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>20.0</td> <td>0.1</td> <td>-20.0</td> <td>Male</td> <td>Apple</td> </tr> <tr> <th>1</th> <td>300.0</td> <td>NaN</td> <td>-10.0</td> <td>Female</td> <td>Orange</td> </tr> <tr> <th>2</th> <td>400.0</td> <td>0.5</td> <td>0.0</td> <td>None</td> <td>Apple</td> </tr> <tr> <th>3</th> <td>NaN</td> <td>0.6</td> <td>-30.0</td> <td>Female</td> <td>Banana</td> </tr> <tr> <th>4</th> <td>100.0</td> <td>NaN</td> <td>NaN</td> <td>Female</td> <td>Pear</td> </tr> </tbody> </table> </div> <p>A <code class="language-plaintext highlighter-rouge">ColumnTransformer</code> stores a list of (name, transformer, columns) tuples as <code class="language-plaintext highlighter-rouge">transformers</code>, which allows different columns to be transformed separately.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="nc">ColumnTransformer</span><span class="p">(</span>
            <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="sh">"</span><span class="s">num</span><span class="sh">"</span><span class="p">,</span> <span class="n">numeric_transformer</span><span class="p">,</span> <span class="p">[</span><span class="sh">"</span><span class="s">n1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">n2</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">n3</span><span class="sh">"</span><span class="p">]),</span>
                <span class="p">(</span><span class="sh">"</span><span class="s">cat</span><span class="sh">"</span><span class="p">,</span> <span class="n">categorical_transformer</span><span class="p">,</span> <span class="p">[</span><span class="sh">"</span><span class="s">c1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">c2</span><span class="sh">"</span><span class="p">]),</span>
            <span class="p">]</span>
        <span class="p">)</span>
</code></pre></div></div> <p>We <code class="language-plaintext highlighter-rouge">fit</code> all transformers on dataset <code class="language-plaintext highlighter-rouge">df</code>, transform dataset <code class="language-plaintext highlighter-rouge">df</code>, and concatenate the results with method <code class="language-plaintext highlighter-rouge">fit_transform</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">preprocessor</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[-1.35411306, -1.95003374, -0.5       ,  0.        ,  1.        ,
         0.        ,  1.        ,  0.        ,  0.        ,  0.        ],
       [ 0.70649377,  0.3441236 ,  0.5       ,  1.        ,  0.        ,
         0.        ,  0.        ,  0.        ,  1.        ,  0.        ],
       [ 1.44242478,  0.3441236 ,  1.5       ,  0.        ,  0.        ,
         1.        ,  1.        ,  0.        ,  0.        ,  0.        ],
       [-0.02943724,  0.91766294, -1.5       ,  1.        ,  0.        ,
         0.        ,  0.        ,  1.        ,  0.        ,  0.        ],
       [-0.76536825,  0.3441236 ,  0.        ,  1.        ,  0.        ,
         0.        ,  0.        ,  0.        ,  0.        ,  1.        ]])
</code></pre></div></div> <p>After fitting the transformers, we can use <code class="language-plaintext highlighter-rouge">preprocessor</code> on new dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_new</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">n1</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">n2</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="bp">None</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">n3</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">c1</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">Male</span><span class="sh">'</span><span class="p">],</span>
      <span class="sh">'</span><span class="s">c2</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="bp">None</span><span class="p">],</span>
    <span class="p">}</span>

<span class="n">df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data_new</span><span class="p">)</span>
<span class="n">df_new</span>

</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>n1</th> <th>n2</th> <th>n3</th> <th>c1</th> <th>c2</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>10</td> <td>None</td> <td>-10</td> <td>Male</td> <td>None</td> </tr> </tbody> </table> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">preprocessor</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">df_new</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[-1.42770616,  0.3441236 ,  0.5       ,  0.        ,  1.        ,
         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])
</code></pre></div></div> <h2 id="design-your-own-transformers">Design Your Own Transformers</h2> <p>We can design custom transformers by defining a subclass of <code class="language-plaintext highlighter-rouge">BaseEstimator</code> and <code class="language-plaintext highlighter-rouge">TransformerMixin</code>. There are three methods we need to implement: <code class="language-plaintext highlighter-rouge">__init__</code> , <code class="language-plaintext highlighter-rouge">fit</code>, and <code class="language-plaintext highlighter-rouge">transform</code>.</p> <p>In the example below, we design a simple transformer to first fill missing values with zeros and divide the values by 10.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>


<span class="k">class</span> <span class="nc">CustomTransformer</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span><span class="o">/</span><span class="mi">10</span>

</code></pre></div></div> <p>Once the custom transformer is initialized, it can be used the same way as any other transformers we discussed before. Here we use the custom transformer on column <code class="language-plaintext highlighter-rouge">"n3"</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">custom_tansformer</span> <span class="o">=</span> <span class="nc">CustomTransformer</span><span class="p">()</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">preprocessor_custom</span> <span class="o">=</span> <span class="nc">ColumnTransformer</span><span class="p">(</span>
            <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="sh">"</span><span class="s">num</span><span class="sh">"</span><span class="p">,</span> <span class="n">numeric_transformer</span><span class="p">,</span> <span class="p">[</span><span class="sh">"</span><span class="s">n1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">n2</span><span class="sh">"</span><span class="p">]),</span>
                <span class="p">(</span><span class="sh">"</span><span class="s">custom</span><span class="sh">"</span><span class="p">,</span> <span class="n">custom_tansformer</span><span class="p">,</span> <span class="p">[</span><span class="sh">"</span><span class="s">n3</span><span class="sh">"</span><span class="p">]),</span>
                <span class="p">(</span><span class="sh">"</span><span class="s">cat</span><span class="sh">"</span><span class="p">,</span> <span class="n">categorical_transformer</span><span class="p">,</span> <span class="p">[</span><span class="sh">"</span><span class="s">c1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">c2</span><span class="sh">"</span><span class="p">]),</span>
            <span class="p">]</span>
        <span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">preprocessor_custom</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[-1.35411306, -1.95003374, -2.        ,  0.        ,  1.        ,
         0.        ,  1.        ,  0.        ,  0.        ,  0.        ],
       [ 0.70649377,  0.3441236 , -1.        ,  1.        ,  0.        ,
         0.        ,  0.        ,  0.        ,  1.        ,  0.        ],
       [ 1.44242478,  0.3441236 ,  0.        ,  0.        ,  0.        ,
         1.        ,  1.        ,  0.        ,  0.        ,  0.        ],
       [-0.02943724,  0.91766294, -3.        ,  1.        ,  0.        ,
         0.        ,  0.        ,  1.        ,  0.        ,  0.        ],
       [-0.76536825,  0.3441236 ,  0.        ,  1.        ,  0.        ,
         0.        ,  0.        ,  0.        ,  0.        ,  1.        ]])
</code></pre></div></div> <h2 id="conclusion">Conclusion</h2> <p>In summary, we discussed how data transformation can be constructed as a pipeline. We can fit a data transformation pipeline on our training dataset and use the same pipeline to transform new dataset.</p>]]></content><author><name></name></author><category term="machine-learning-engineering"/><category term="feature-engineering,"/><category term="pipeline,"/><category term="scikit-learn"/><summary type="html"><![CDATA[Build a pipeline to do feature engineering with Scikit-learn.]]></summary></entry><entry><title type="html">Top Recent Machine Learning Papers</title><link href="https://weijianzhg.github.io/blog/2017/top-recent-machine-learning-papers/" rel="alternate" type="text/html" title="Top Recent Machine Learning Papers"/><published>2017-09-05T07:10:04+00:00</published><updated>2017-09-05T07:10:04+00:00</updated><id>https://weijianzhg.github.io/blog/2017/top-recent-machine-learning-papers</id><content type="html" xml:base="https://weijianzhg.github.io/blog/2017/top-recent-machine-learning-papers/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Visualizing Machine Learning Papers</title><link href="https://weijianzhg.github.io/blog/2017/visualizing-machine-learning-papers/" rel="alternate" type="text/html" title="Visualizing Machine Learning Papers"/><published>2017-08-24T17:31:35+00:00</published><updated>2017-08-24T17:31:35+00:00</updated><id>https://weijianzhg.github.io/blog/2017/visualizing-machine-learning-papers</id><content type="html" xml:base="https://weijianzhg.github.io/blog/2017/visualizing-machine-learning-papers/"><![CDATA[]]></content><author><name></name></author></entry></feed>